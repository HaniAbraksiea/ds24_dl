{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f252b9e",
   "metadata": {},
   "source": [
    "# Chattbot med RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "**Datum:** 27 maj 2025  \n",
    "**Student:** Hani Abraksiea  \n",
    "**Kurs:** Data Scientist – EC Utbildning  \n",
    "**Syfte:**  \n",
    "Syftet med detta projekt är att bygga en chattbot som använder RAG-teknik för att svara på frågor utifrån innehåll i en PDF-fil. Modellen begränsar sina svar till det material som finns i dokumentet, och svarar \"Det vet jag inte\" om informationen inte finns.\n",
    "\n",
    "Målet är att visa teknisk förståelse för RAG, samt kunna resonera kring användning, utmaningar och etiska perspektiv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a374d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hani7\\OneDrive\\Dokument\\Data_scientist_EC_utbildning\\07_dl\\Kunskapkontrol_2\\genai_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Ladda API-nyckel från .env\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019efc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks: 254\n"
     ]
    }
   ],
   "source": [
    "# Läs in PDF (Magisteruppsats)\n",
    "reader = PdfReader(\"Magisteruppsats.pdf\")\n",
    "text = \"\".join([page.extract_text() for page in reader.pages])\n",
    "\n",
    "# Dela upp i chunks\n",
    "chunk_size = 1000\n",
    "overlap = 200\n",
    "chunks = []\n",
    "for i in range(0, len(text), chunk_size - overlap):\n",
    "    chunks.append(text[i:i + chunk_size])\n",
    "\n",
    "print(f\"Antal chunks: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da74235",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"models/embedding-001\"\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    return [genai.embed_content(\n",
    "        model=embedding_model,\n",
    "        content=txt,\n",
    "        task_type=\"retrieval_document\"\n",
    "    )[\"embedding\"] for txt in text_list]\n",
    "\n",
    "chunk_embeddings = get_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4bfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def semantic_search(query, chunks, embeddings, k=5):\n",
    "    query_embedding = genai.embed_content(\n",
    "        model=embedding_model,\n",
    "        content=query,\n",
    "        task_type=\"retrieval_query\"\n",
    "    )[\"embedding\"]\n",
    "    \n",
    "    scores = [(i, cosine_similarity(query_embedding, emb)) for i, emb in enumerate(embeddings)]\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_chunks = [chunks[i] for i, _ in scores[:k]]\n",
    "    \n",
    "    return \"\\n\".join(top_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801d9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "def generate_answer(query):\n",
    "    context = semantic_search(query, chunks, chunk_embeddings)\n",
    "    prompt = f\"\"\"\n",
    "Du är en hjälpsam assistent. Svara bara baserat på följande kontext:\n",
    "{context}\n",
    "\n",
    "Fråga: {query}\n",
    "Om svaret inte finns i kontexten, säg \"Det vet jag inte.\"\n",
    "\"\"\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bebfd3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"question\": \"Vilken typ av intervjuer användes i studien?\",\n",
    "        \"expected_contains\": \"semistrukturerade\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Vilken kommun är studien baserad på?\",\n",
    "        \"expected_contains\": \"Nyköpings\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Vilket arbetssätt handlar uppsatsen om?\",\n",
    "        \"expected_contains\": \"Agila arbetssätt inom IT-avdelningen i Nyköpings kommun.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Vilket år grundades kommunen?\",\n",
    "        \"expected_contains\": \"Det vet jag inte\" # Ej med i dokumentet\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c73d5d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fråga: Vilken typ av intervjuer användes i studien?\n",
      "Svar: Studien använde semistrukturerade intervjuer.\n",
      "\n",
      "Godkänt? ✓\n",
      "----------------------------------------\n",
      "Fråga: Vilken kommun är studien baserad på?\n",
      "Svar: Studien är baserad på Nyköpings kommun.\n",
      "\n",
      "Godkänt? ✓\n",
      "----------------------------------------\n",
      "Fråga: Vilket arbetssätt handlar uppsatsen om?\n",
      "Svar: Uppsatsen handlar om agila arbetssätt inom IT-avdelningen i Nyköpings kommun.\n",
      "\n",
      "Godkänt? ✓\n",
      "----------------------------------------\n",
      "Fråga: Vilket år grundades kommunen?\n",
      "Svar: Det vet jag inte.\n",
      "\n",
      "Godkänt? ✓\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for case in test_cases:\n",
    "    print(\"Fråga:\", case[\"question\"])\n",
    "    answer = generate_answer(case[\"question\"])\n",
    "    print(\"Svar:\", answer)\n",
    "    print(\"Godkänt?\" , \"✓\" if case[\"expected_contains\"].lower() in answer.lower() else \"✗\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c31afa",
   "metadata": {},
   "source": [
    "## Reflektion: Användning, möjligheter och utmaningar\n",
    "\n",
    "Chattboten använder Retrieval-Augmented Generation (RAG), en metod där en språkmodell först hämtar relevant information från en specifik källa – i detta fall min magisteruppsats – och därefter genererar ett svar baserat på den. Detta tillvägagångssätt minskar risken för att modellen \"hittar på\" information och ger mer kontextmedvetna och korrekta svar.\n",
    "\n",
    "### Möjlig användning:\n",
    "- Forskare som snabbt vill ställa frågor om innehållet i sina egna studier\n",
    "- Studenter som vill förstå, citera eller referera akademiska texter korrekt\n",
    "- Journalister som analyserar större dokument eller rapporter\n",
    "- Myndigheter eller organisationer som vill erbjuda sökbarhet i interna dokument\n",
    "\n",
    "### Etiska och tekniska utmaningar:\n",
    "- AI:n kan ändå ge osäkra eller vaga svar om kontexten är otydlig eller ofullständig\n",
    "- RAG-system måste hantera upphovsrätt korrekt om externa dokument används\n",
    "- Det finns risk för att användaren tolkar svaren som absoluta sanningar\n",
    "- Om systemet används med känsliga eller personliga dokument måste GDPR och datasäkerhet beaktas\n",
    "\n",
    "### Affärspotential:\n",
    "- Ett kraftfullt verktyg för universitet, bibliotek eller forskningsdatabaser\n",
    "- Möjlighet att integrera i intranät, dokumentarkiv eller e-tjänster\n",
    "- Kundserviceverktyg för organisationer med omfattande PDF-manualer eller policyer\n",
    "\n",
    "### Slutsats:\n",
    "Detta projekt visar att RAG-teknik kan skapa mer tillförlitliga och ansvarsfulla AI-assistenter. Genom att begränsa modellens svar till specifika dokument blir interaktionen både mer trovärdig och användbar – särskilt i kunskapsintensiva miljöer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
